# -*- coding: utf-8 -*-
"""SemanticSimilarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10W8A_LTWI6w-RAsI8GJsT8F1DYFAhnzH
"""

pip install sentence_transformers

#Install necessary packages
from google.colab import drive
from sentence_transformers import SentenceTransformer, util
import pandas as pd
import numpy as np

#Mount Drive
drive.mount("/content/gdrive")

#Initialize SentenceTransformer model
model=SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')

# Commented out IPython magic to ensure Python compatibility.
# % cd /content/gdrive/MyDrive

#Load the dataset
df=pd.read_csv("Text_Similarity_Dataset.csv",header=[0])
data=np.array(df.iloc[:,:])

output=open("SimilarityScores.csv","w")
print("Opened file for writing.....\n")

#Column headers
output.write("Unique_ID,Similarity_Score\n")

i=0
for i in range(len(data)):
  #write Unique_ID to file
  output.write(str(data[i][0]))

  sent1=data[i][1] #text1
  sent2=data[i][2] #text2  

  #encode sentence to get their embedding
  embed1=model.encode(sent1,convert_to_tensor=True)
  embed2=model.encode(sent2,convert_to_tensor=True)

  #compute similarity score of two embeddings
  cosine_scores=util.pytorch_cos_sim(embed1,embed2)
  score=cosine_scores.item()  

  print(f"Processing Row {i+1}, Similarity Score : {score}")  

  #Write similarity score to file
  output.write(","+str(score))
  output.write("\n")

output.close()
print(f"\n File Closed... {i+1} records created")