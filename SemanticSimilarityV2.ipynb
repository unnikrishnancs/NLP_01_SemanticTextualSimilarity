{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rough_SemanticSimilarity.ipynb","provenance":[{"file_id":"10W8A_LTWI6w-RAsI8GJsT8F1DYFAhnzH","timestamp":1622305061012},{"file_id":"15-sDphFGlq3p8zlKkXViNuvbo9UlGIYG","timestamp":1622272564951}],"collapsed_sections":[],"authorship_tag":"ABX9TyNSG007bVNJxWsu8cRu0Z73"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"IMXjYWVT5rLN"},"source":["#pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"erzlnYTL6NqU"},"source":["pip install sentence-transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juJ8633T6X2S"},"source":["#pip install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ir5Jqveu0YwF"},"source":["from google.colab import drive\n","from sentence_transformers import SentenceTransformer, util\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9A_GfBZ5EIB"},"source":["drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cN0Il9J85cvj"},"source":["% cd /content/gdrive/MyDrive/NLP/SemanticTextualSimilarity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNUeU_FK8xK2"},"source":["#Initialize model\n","#model=SentenceTransformer('bert-base-uncased') #high scores for all\n","#model=SentenceTransformer('paraphrase-MiniLM-L12-v2') #scores in negative also\n","model=SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSRd21B7ppbr"},"source":["#read the dataset\n","df=pd.read_csv(\"Similarity_Dataset_100rows.csv\",header=[0])\n","data=np.array(df.iloc[:150,:])\n","print(type(data))\n","#print(data[\"Unique_ID\"],data[\"text1\"],data[\"text2\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRXCyY-X4Gy1"},"source":["'''\n","for i in range(len(data)):\n","  print(data[i,0])\n","  print(data[i,1])\n","  print(data[i,2])\n","  print(\"\\n\\n\")\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVRRhEsm88EG"},"source":["output=open(\"Scores.txt\",\"w\")\n","print(\"Opened file for writing.....\")\n","\n","output.write(\"Unique_ID,Similarity Score\\n\")\n","i=0\n","for i in range(len(data)):\n","  output.write(str(data[i][0]))\n","\n","  sent1=data[i][1]\n","  sent2=data[i][2]\n","\n","  #encode sentence to get their embedding\n","  embed1=model.encode(sent1,convert_to_tensor=True)\n","  embed2=model.encode(sent2,convert_to_tensor=True)\n","\n","  #compute similarity score of two embeddings\n","  cosine_scores=util.pytorch_cos_sim(embed1,embed2)\n","\n","  print(\"Sentence1 : \",sent1)\n","  print(\"Sentence2 : \",sent2)  \n","  score=cosine_scores.item()  \n","  print(\"Similarity Score: \",score)\n","\n","  #Write details to file  \n","  output.write(\",\"+str(score))\n","  output.write(\"\\n\")\n","\n","output.close()\n","print(f\"File Closed. {i+1} records created\")"],"execution_count":null,"outputs":[]}]}